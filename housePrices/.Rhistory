responseSkew <- BoxCoxTrans(SalePrice)
#hist(predict(responseSkew, SalePrice))
SalePriceTrans <- predict(responseSkew, SalePrice)
trainsetTrans<-trainsetReg
for(i in 1:ncol(trainsetTrans)){
if(class(trainsetTrans[,i])!="factor"){
responseSkew <- BoxCoxTrans(trainsetTrans[,i])
trainsetTrans[,i]<-predict(responseSkew, trainsetTrans[,i])
}
}
##############################  CORRELATIONS  ##############################
library(corrplot)
correlations<-cor(subset(trainsetTrans, select=sapply(trainsetTrans, is.numeric)))
corrplot(correlations, order = "hclust")
highCorr<- findCorrelation(correlations, cutoff = .75)
colnames(trainsetTrans)[highCorr]
##############################  Analyzing HOUSE PRICES DATA
##############################  LIBRARIES  AND IMPORT DATA ##################################
library(tidyverse)
library(caret)
library(skimr)
library(xgboost)
library(e1071)
cat("\014")
rm(list = ls())
source("fillingMethodJulien.R")
source("./ausiliaryFunctions/convertToFactorDataset.R")
source("./ausiliaryFunctions/whatAreFactors.R")
source("./ausiliaryFunctions/scaleNumericalData.R")
source("./ausiliaryFunctions/percentageNumCol.R")
trainset<-read.csv2("./input/train.csv", sep =",")
testset<-read.csv2("./input/test.csv", sep =",")
trainset<-trainset %>% select(-Id)
SalePrice<-trainset$SalePrice
trainset<-trainset %>% select(-SalePrice)
skimmed <- skim_to_wide(trainset)
skimmed[, c(1:4, 8:9, 13, 15:15)]
namesFactor<-whatAreFactors(trainset)
percentageNumCol(trainset)
percentageNumCol(trainset) # to see how if I will remove to many columns
# One-Hot Encoding
# Creating dummy variables is converting a categorical variable to as many binary variables as here are categories.
dummies_model <- dummyVars( ~ ., data=trainset)
# Create the dummy variables using predict. The Y variable will not be present in trainData_mat.
# The Y variable (SalePrice) will not be present in trainData_mat.
trainData_mat <- predict(dummies_model, newdata = trainset)
method <- "julien"
trainsetReg<-data.frame(trainData_mat)
# # variance zero: I delete them
nzv <- nearZeroVar(trainsetReg, saveMetrics = TRUE)
# this is the case in which we have very low variance and possibles NA values that we
# can't treat with knn
trainsetNoVar<- trainsetReg[, !nzv[,"nzv"]]
convertToFactorDataset(trainsetNoVar,namesFactor) %>% percentageNumCol(.,2,ncol(trainset))
naPercRow<-rowSums(is.na(trainsetNoVar))/ncol(trainsetNoVar)
hist(naPercRow) # We don't see a row with a lot of NA
naPercCol<-colSums(is.na(trainsetNoVar))/nrow(trainsetNoVar)
hist(naPercCol) # we have some columns with only NA
hist(naPercRow) # We don't see a row with a lot of NA
naPercCol<-colSums(is.na(trainsetNoVar))/nrow(trainsetNoVar)
hist(naPercCol) # we have some columns with only NA
hist(naPercCol) # we have some columns with only NA (see values)
threshold<-0.5 # over this percentage we remove the column
enoughdata<-which(naPercCol<threshold)
trainsetNoVar<-trainsetNoVar[,enoughdata] # i remove definitively the columns with too many NA
naPercCol<-colSums(is.na(trainsetNoVar))/nrow(trainsetNoVar) # i compute again what are the interesting columns
naPercCol<-sort(naPercCol[naPercCol>0])
namesNAColumns<-names(naPercCol)
#trainsetRegFilled<-fillingBySimpleKNN(trainsetNoVar,namesNAColumns)
#saveRDS(trainsetRegFilled,"trainsetRegFilled.RDS")
trainsetRegFilled<-readRDS("trainsetRegFilled.RDS")
trainsetRegFilled %>% percentageNumCol(.,2,ncol(trainset))
# we recover predictor with near zero variance but with possible NA
trainsetReg <- cbind(trainsetRegFilled %>% select(namesNAColumns),
trainsetReg %>% select(-namesNAColumns))
# we remove the ones that have NA
resNA<- colSums(is.na(trainsetReg))
resNA<- names(resNA[resNA>0])
trainsetReg<-trainsetReg %>% select(-resNA)
trainsetReg<-convertToFactorDataset(trainsetReg, namesFactor)
trainsetReg %>% percentageNumCol(.,2,ncol(trainset))
convertToFactorDataset(trainsetNoVar,namesFactor) %>% percentageNumCol(.,2,ncol(trainset))
percentageNumCol(trainset) # to see how if I will remove to many columns
colnames(trainsetReg)
grep("Pool",colnames(trainsetReg))
hist(SalePrice)
#hist(SalePrice)
responseSkew <- BoxCoxTrans(SalePrice)
#hist(predict(responseSkew, SalePrice))
SalePriceTrans <- predict(responseSkew, SalePrice)
trainsetTrans<-trainsetReg
for(i in 1:ncol(trainsetTrans)){
if(class(trainsetTrans[,i])!="factor"){
responseSkew <- BoxCoxTrans(trainsetTrans[,i])
trainsetTrans[,i]<-predict(responseSkew, trainsetTrans[,i])
}
}
library(corrplot)
correlations<-cor(subset(trainsetTrans, select=sapply(trainsetTrans, is.numeric)))
corrplot(correlations, order = "hclust")
highCorr<- findCorrelation(correlations, cutoff = .75)
trainsetTransNoCor<-trainsetTrans[,-highCorr]
trainsetTransNoCorScaled<-scaleNumericalData(trainsetTransNoCor)
trainingIndex<-createDataPartition(SalePrice, p = 0.9, list = FALSE)
# Define the training control
fitControl <- trainControl(
method = 'cv',                   # k-fold cross validation
number = 5                    # number of folds
)
model <- train(trainingTransNoCorScaled, SalePriceTransTrain,
method = "lm",
tuneLength=5,
trControl = fitControl
)
library(tidyverse)
library(caret)
library(skimr)
library(xgboost)
library(e1071)
cat("\014")
rm(list = ls())
source("fillingMethodJulien.R")
source("./ausiliaryFunctions/convertToFactorDataset.R")
source("./ausiliaryFunctions/whatAreFactors.R")
source("./ausiliaryFunctions/scaleNumericalData.R")
source("./ausiliaryFunctions/percentageNumCol.R")
trainset<-read.csv2("./input/train.csv", sep =",")
testset<-read.csv2("./input/test.csv", sep =",")
trainset<-trainset %>% select(-Id)
SalePrice<-trainset$SalePrice
trainset<-trainset %>% select(-SalePrice)
skimmed <- skim_to_wide(trainset)
skimmed[, c(1:4, 8:9, 13, 15:15)]
namesFactor<-whatAreFactors(trainset) # to mantain memory after one hot encounding what are the factory variables
percentageNumCol(trainset) # to see how if I will remove to many columns
##############################  ONE-HOT ENCODING ##################################
# One-Hot Encoding
# Creating dummy variables is converting a categorical variable to as many binary variables as here are categories.
dummies_model <- dummyVars( ~ ., data=trainset)
# Create the dummy variables using predict. The Y variable will not be present in trainData_mat.
# The Y variable (SalePrice) will not be present in trainData_mat.
trainData_mat <- predict(dummies_model, newdata = trainset)
##############################  FILL THE NA VALUES ##################################
method <- "julien"
trainsetReg<-data.frame(trainData_mat)
# # variance zero: I delete them
nzv <- nearZeroVar(trainsetReg, saveMetrics = TRUE)
# this is the case in which we have very low variance and possibles NA values that we
# can't treat with knn
trainsetNoVar<- trainsetReg[, !nzv[,"nzv"]]
convertToFactorDataset(trainsetNoVar,namesFactor) %>% percentageNumCol(.,2,ncol(trainset))
# we have reduce the number of columns for this reason:
# we don't want predictor with low variability and NA.
# But we will recover predictors with low variability but without N
# Computation of NA percentage
naPercRow<-rowSums(is.na(trainsetNoVar))/ncol(trainsetNoVar)
hist(naPercRow) # We don't see a row with a lot of NA (see values)
naPercCol<-colSums(is.na(trainsetNoVar))/nrow(trainsetNoVar)
hist(naPercCol) # we have some columns with only NA (see values)
threshold<-0.5 # over this percentage we remove the column
enoughdata<-which(naPercCol<threshold)
trainsetNoVar<-trainsetNoVar[,enoughdata] # i remove definitively the columns with too many NA
naPercCol<-colSums(is.na(trainsetNoVar))/nrow(trainsetNoVar) # i compute again what are the interesting columns
naPercCol<-sort(naPercCol[naPercCol>0])
namesNAColumns<-names(naPercCol)
# filling methods
if (method == "julien"){
#trainsetRegFilled<-fillingBySimpleKNN(trainsetNoVar,namesNAColumns)
#saveRDS(trainsetRegFilled,"trainsetRegFilled.RDS")
trainsetRegFilled<-readRDS("trainsetRegFilled.RDS")
trainsetRegFilled %>% percentageNumCol(.,2,ncol(trainset))
# we recover predictor with near zero variance but with possible NA
trainsetReg <- cbind(trainsetRegFilled %>% select(namesNAColumns),
trainsetReg %>% select(-namesNAColumns))
# we remove the ones that have NA
resNA<- colSums(is.na(trainsetReg))
resNA<- names(resNA[resNA>0])
trainsetReg<-trainsetReg %>% select(-resNA)
trainsetReg<-convertToFactorDataset(trainsetReg, namesFactor)
trainsetReg %>% percentageNumCol(.,2,ncol(trainset))
}else if(method =="valerio"){
next
}
# at this point i've the columns with NA filled and the oldest one with near zero variance
##############################  SOLVING PROBLEM OF SKEWNESS ##################################
#hist(SalePrice)
responseSkew <- BoxCoxTrans(SalePrice)
#hist(predict(responseSkew, SalePrice))
SalePriceTrans <- predict(responseSkew, SalePrice)
trainsetTrans<-trainsetReg
for(i in 1:ncol(trainsetTrans)){
if(class(trainsetTrans[,i])!="factor"){
responseSkew <- BoxCoxTrans(trainsetTrans[,i])
trainsetTrans[,i]<-predict(responseSkew, trainsetTrans[,i])
}
}
##############################  CORRELATIONS  ##############################
# we remove predictors with too big correlations
library(corrplot)
correlations<-cor(subset(trainsetTrans, select=sapply(trainsetTrans, is.numeric)))
corrplot(correlations, order = "hclust")
highCorr<- findCorrelation(correlations, cutoff = .75)
trainsetTransNoCor<-trainsetTrans[,-highCorr]
##############################  DEFINING A MACHINE LEARNING MODEL  ##############################
# we have three datasets as input:  trainsetRegFilled ;trainsetTrans; trainsetTransNoCor
# we have two possible outputs: SalePrice; SalePriceTrans
trainsetTransNoCorScaled<-scaleNumericalData(trainsetTransNoCor)
trainingIndex<-createDataPartition(SalePrice, p = 0.9, list = FALSE)
# Define the training control
fitControl <- trainControl(
method = 'cv',                   # k-fold cross validation
number = 5                    # number of folds
)
######## linear model -----
trainingTransNoCorScaled<-trainsetTransNoCorScaled[trainingIndex,]
SalePriceTransTrain<-SalePriceTrans[trainingIndex]
model <- train(trainingTransNoCorScaled, SalePriceTransTrain,
method = "lm",
tuneLength=5,
trControl = fitControl
)
model <- train(trainingTransNoCorScaled, SalePriceTransTrain,
method = "lm",
trControl = fitControl
)
model <- train(trainingTransNoCorScaled, SalePriceTransTrain,
method = "lm"
)
warnigns()
warnings()
dummies_model <- dummyVars(~ ., data=trainingTransNoCorScaled)
# Create the dummy variables using predict. The Y variable will not be present in trainData_mat.
# The Y variable (SalePrice) will not be present in trainData_mat.
trainData_mat <- predict(dummies_model, newdata = trainingTransNoCorScaled)
model_rf <- train(trainData_mat, SalePriceTransTrain,
method='rf',
tuneLength=5,
trControl = fitControl)
##############################  Analyzing HOUSE PRICES DATA
##############################  LIBRARIES  AND IMPORT DATA ##################################
library(tidyverse)
library(caret)
library(skimr)
library(xgboost)
library(e1071)
cat("\014")
rm(list = ls())
source("fillingMethodJulien.R")
source("./ausiliaryFunctions/convertToFactorDataset.R")
source("./ausiliaryFunctions/whatAreFactors.R")
source("./ausiliaryFunctions/scaleNumericalData.R")
source("./ausiliaryFunctions/percentageNumCol.R")
trainset<-read.csv2("./input/train.csv", sep =",")
testset<-read.csv2("./input/test.csv", sep =",")
trainset<-trainset %>% select(-Id)
SalePrice<-trainset$SalePrice
trainset<-trainset %>% select(-SalePrice)
skimmed <- skim_to_wide(trainset)
skimmed[, c(1:4, 8:9, 13, 15:15)]
namesFactor<-whatAreFactors(trainset) # to mantain memory after one hot encounding what are the factory variables
percentageNumCol(trainset) # to see how if I will remove to many columns
##############################  ONE-HOT ENCODING ##################################
# One-Hot Encoding
# Creating dummy variables is converting a categorical variable to as many binary variables as here are categories.
dummies_model <- dummyVars( ~ ., data=trainset)
# Create the dummy variables using predict. The Y variable will not be present in trainData_mat.
# The Y variable (SalePrice) will not be present in trainData_mat.
trainData_mat <- predict(dummies_model, newdata = trainset)
##############################  FILL THE NA VALUES ##################################
method <- "julien"
trainsetReg<-data.frame(trainData_mat)
# # variance zero: I delete them
nzv <- nearZeroVar(trainsetReg, saveMetrics = TRUE)
# this is the case in which we have very low variance and possibles NA values that we
# can't treat with knn
trainsetNoVar<- trainsetReg[, !nzv[,"nzv"]]
convertToFactorDataset(trainsetNoVar,namesFactor) %>% percentageNumCol(.,2,ncol(trainset))
# we have reduce the number of columns for this reason:
# we don't want predictor with low variability and NA.
# But we will recover predictors with low variability but without N
# Computation of NA percentage
naPercRow<-rowSums(is.na(trainsetNoVar))/ncol(trainsetNoVar)
hist(naPercRow) # We don't see a row with a lot of NA (see values)
naPercCol<-colSums(is.na(trainsetNoVar))/nrow(trainsetNoVar)
hist(naPercCol) # we have some columns with only NA (see values)
threshold<-0.5 # over this percentage we remove the column
enoughdata<-which(naPercCol<threshold)
trainsetNoVar<-trainsetNoVar[,enoughdata] # i remove definitively the columns with too many NA
naPercCol<-colSums(is.na(trainsetNoVar))/nrow(trainsetNoVar) # i compute again what are the interesting columns
naPercCol<-sort(naPercCol[naPercCol>0])
namesNAColumns<-names(naPercCol)
# filling methods
if (method == "julien"){
#trainsetRegFilled<-fillingBySimpleKNN(trainsetNoVar,namesNAColumns)
#saveRDS(trainsetRegFilled,"trainsetRegFilled.RDS")
trainsetRegFilled<-readRDS("trainsetRegFilled.RDS")
trainsetRegFilled %>% percentageNumCol(.,2,ncol(trainset))
# we recover predictor with near zero variance but with possible NA
trainsetReg <- cbind(trainsetRegFilled %>% select(namesNAColumns),
trainsetReg %>% select(-namesNAColumns))
# we remove the ones that have NA
resNA<- colSums(is.na(trainsetReg))
resNA<- names(resNA[resNA>0])
trainsetReg<-trainsetReg %>% select(-resNA)
trainsetReg<-convertToFactorDataset(trainsetReg, namesFactor)
trainsetReg %>% percentageNumCol(.,2,ncol(trainset))
}else if(method =="valerio"){
next
}
# at this point i've the columns with NA filled and the oldest one with near zero variance
##############################  SOLVING PROBLEM OF SKEWNESS ##################################
#hist(SalePrice)
responseSkew <- BoxCoxTrans(SalePrice)
#hist(predict(responseSkew, SalePrice))
SalePriceTrans <- predict(responseSkew, SalePrice)
trainsetTrans<-trainsetReg
for(i in 1:ncol(trainsetTrans)){
if(class(trainsetTrans[,i])!="factor"){
responseSkew <- BoxCoxTrans(trainsetTrans[,i])
trainsetTrans[,i]<-predict(responseSkew, trainsetTrans[,i])
}
}
##############################  CORRELATIONS  ##############################
# we remove predictors with too big correlations
library(corrplot)
correlations<-cor(subset(trainsetTrans, select=sapply(trainsetTrans, is.numeric)))
corrplot(correlations, order = "hclust")
highCorr<- findCorrelation(correlations, cutoff = .75)
trainsetTransNoCor<-trainsetTrans[,-highCorr]
trainsetTransNoCorScaled<-scaleNumericalData(trainsetTransNoCor)
trainingIndex<-createDataPartition(SalePrice, p = 0.9, list = FALSE)
# Define the training control
fitControl <- trainControl(
method = 'cv',                   # k-fold cross validation
number = 5                    # number of folds
)
########  SVM -----
trainingTransNoCorScaled<-trainsetTransNoCorScaled[trainingIndex,]
SalePriceTransTrain<-SalePriceTrans[trainingIndex]
nzv <- nearZeroVar(trainingTransNoCorScaled, saveMetrics = TRUE)
# this is the case in which we have very low variance and possibles NA values that we
# can't treat with knn
trainingTransNoCorScaledNovar<- trainingTransNoCorScaled[, !nzv[,"nzv"]]
svmRTuned <- train(trainingTransNoCorScaledNovar, SalePriceTransTrain,
method = "svmRadial",
tuneLength = 14,
trControl = fitControl
)
SalePriceTransTrain
str(trainingTransNoCorScaledNovar)
svmRTuned <- train(trainingTransNoCorScaledNovar, SalePriceTransTrain,
method = "svmRadial",
tuneLength = 14,
trControl = fitControl
)
ksvm(x = trainingTransNoCorScaledNovar, y = SalePriceTransTrain,
kernel ="rbfdot", kpar = "automatic", C = 1, epsilon = 0.1)
library(kernlab)
ksvm(x = trainingTransNoCorScaledNovar, y = SalePriceTransTrain,
kernel ="rbfdot", kpar = "automatic", C = 1, epsilon = 0.1)
# this is the case in which we have very low variance and possibles NA values that we
# can't treat with knn
trainingTransNoCorScaledNovar<- trainingTransNoCorScaled[, !nzv[,"nzv"]]
dummies_model <- dummyVars(~ ., data=trainingTransNoCorScaledNovar)
trainData_mat <- predict(dummies_model, newdata = trainingTransNoCorScaledNovar)
svmRTuned <- train(trainData_mat, SalePriceTransTrain,
method = "svmRadial",
tuneLength = 14,
trControl = fitControl
)
plot(svmRTuned)
svmRTuned
fitControl
##############################  Analyzing HOUSE PRICES DATA
##############################  LIBRARIES  AND IMPORT DATA ##################################
library(tidyverse)
library(caret)
library(skimr)
library(xgboost)
library(e1071)
cat("\014")
rm(list = ls())
source("fillingMethodJulien.R")
source("./ausiliaryFunctions/convertToFactorDataset.R")
source("./ausiliaryFunctions/whatAreFactors.R")
source("./ausiliaryFunctions/scaleNumericalData.R")
source("./ausiliaryFunctions/percentageNumCol.R")
trainset<-read.csv2("./input/train.csv", sep =",")
testset<-read.csv2("./input/test.csv", sep =",")
trainset<-trainset %>% select(-Id)
SalePrice<-trainset$SalePrice
trainset<-trainset %>% select(-SalePrice)
skimmed <- skim_to_wide(trainset)
skimmed[, c(1:4, 8:9, 13, 15:15)]
namesFactor<-whatAreFactors(trainset) # to mantain memory after one hot encounding what are the factory variables
percentageNumCol(trainset) # to see how if I will remove to many columns
##############################  ONE-HOT ENCODING ##################################
# One-Hot Encoding
# Creating dummy variables is converting a categorical variable to as many binary variables as here are categories.
dummies_model <- dummyVars( ~ ., data=trainset)
# Create the dummy variables using predict. The Y variable will not be present in trainData_mat.
# The Y variable (SalePrice) will not be present in trainData_mat.
trainData_mat <- predict(dummies_model, newdata = trainset)
##############################  FILL THE NA VALUES ##################################
method <- "julien"
trainsetReg<-data.frame(trainData_mat)
# # variance zero: I delete them
nzv <- nearZeroVar(trainsetReg, saveMetrics = TRUE)
# this is the case in which we have very low variance and possibles NA values that we
# can't treat with knn
trainsetNoVar<- trainsetReg[, !nzv[,"nzv"]]
convertToFactorDataset(trainsetNoVar,namesFactor) %>% percentageNumCol(.,2,ncol(trainset))
# we have reduce the number of columns for this reason:
# we don't want predictor with low variability and NA.
# But we will recover predictors with low variability but without N
# Computation of NA percentage
naPercRow<-rowSums(is.na(trainsetNoVar))/ncol(trainsetNoVar)
hist(naPercRow) # We don't see a row with a lot of NA (see values)
naPercCol<-colSums(is.na(trainsetNoVar))/nrow(trainsetNoVar)
hist(naPercCol) # we have some columns with only NA (see values)
threshold<-0.5 # over this percentage we remove the column
enoughdata<-which(naPercCol<threshold)
trainsetNoVar<-trainsetNoVar[,enoughdata] # i remove definitively the columns with too many NA
naPercCol<-colSums(is.na(trainsetNoVar))/nrow(trainsetNoVar) # i compute again what are the interesting columns
naPercCol<-sort(naPercCol[naPercCol>0])
namesNAColumns<-names(naPercCol)
# filling methods
if (method == "julien"){
#trainsetRegFilled<-fillingBySimpleKNN(trainsetNoVar,namesNAColumns)
#saveRDS(trainsetRegFilled,"trainsetRegFilled.RDS")
trainsetRegFilled<-readRDS("trainsetRegFilled.RDS")
trainsetRegFilled %>% percentageNumCol(.,2,ncol(trainset))
# we recover predictor with near zero variance but with possible NA
trainsetReg <- cbind(trainsetRegFilled %>% select(namesNAColumns),
trainsetReg %>% select(-namesNAColumns))
# we remove the ones that have NA
resNA<- colSums(is.na(trainsetReg))
resNA<- names(resNA[resNA>0])
trainsetReg<-trainsetReg %>% select(-resNA)
trainsetReg<-convertToFactorDataset(trainsetReg, namesFactor)
trainsetReg %>% percentageNumCol(.,2,ncol(trainset))
}else if(method =="valerio"){
next
}
# at this point i've the columns with NA filled and the oldest one with near zero variance
##############################  SOLVING PROBLEM OF SKEWNESS ##################################
#hist(SalePrice)
responseSkew <- BoxCoxTrans(SalePrice)
#hist(predict(responseSkew, SalePrice))
SalePriceTrans <- predict(responseSkew, SalePrice)
trainsetTrans<-trainsetReg
for(i in 1:ncol(trainsetTrans)){
if(class(trainsetTrans[,i])!="factor"){
responseSkew <- BoxCoxTrans(trainsetTrans[,i])
trainsetTrans[,i]<-predict(responseSkew, trainsetTrans[,i])
}
}
library(corrplot)
correlations<-cor(subset(trainsetTrans, select=sapply(trainsetTrans, is.numeric)))
corrplot(correlations, order = "hclust")
highCorr<- findCorrelation(correlations, cutoff = .75)
trainsetTransNoCor<-trainsetTrans[,-highCorr]
trainsetTransNoCorScaled<-scaleNumericalData(trainsetTransNoCor)
trainingIndex<-createDataPartition(SalePrice, p = 0.9, list = FALSE)
# Define the training control
fitControl <- trainControl(
method = 'cv',                   # k-fold cross validation
number = 5                    # number of folds
)
########  SVM -----
trainingTransNoCorScaled<-trainsetTransNoCorScaled[trainingIndex,]
SalePriceTransTrain<-SalePriceTrans[trainingIndex]
nzv <- nearZeroVar(trainingTransNoCorScaled, saveMetrics = TRUE)
# this is the case in which we have very low variance and possibles NA values that we
# can't treat with knn
trainingTransNoCorScaledNovar<- trainingTransNoCorScaled[, !nzv[,"nzv"]]
dummies_model <- dummyVars(~ ., data=trainingTransNoCorScaledNovar)
trainData_mat <- predict(dummies_model, newdata = trainingTransNoCorScaledNovar)
svmRTuned <- train(trainData_mat, SalePriceTransTrain,
method = "svmRadial",
tuneLength = 14,
trControl = fitControl
)
plot(svmRTuned)
trainingTransNoCorScaled<-trainsetTransNoCorScaled[trainingIndex,]
SalePriceTransTrain<-SalePriceTrans[trainingIndex]
dummies_model <- dummyVars(~ ., data=trainingTransNoCorScaled)
# Create the dummy variables using predict. The Y variable will not be present in trainData_mat.
# The Y variable (SalePrice) will not be present in trainData_mat.
trainData_mat <- predict(dummies_model, newdata = trainingTransNoCorScaled)
model_rf <- train(trainData_mat, SalePriceTransTrain,
method='rf',
tuneLength=5,
trControl = fitControl)
plot(model_rf)
model_rf
saveRDS(model_rf,"./dataSaved/model_rf.RDS")
trainingTransNoCorScaled<-trainsetTransNoCorScaled[trainingIndex,]
SalePriceTransTrain<-SalePriceTrans[trainingIndex]
dummies_model <- dummyVars(~ ., data=trainingTransNoCorScaled)
# Create the dummy variables using predict. The Y variable will not be present in trainData_mat.
# The Y variable (SalePrice) will not be present in trainData_mat.
trainData_mat <- predict(dummies_model, newdata = trainingTransNoCorScaled)
model <- train(trainData_mat, SalePriceTransTrain,
method = "lm"
)
warnings()
library(doParallel)
cl <- makePSOCKcluster(5)
cl
registerDoParallel(cl)
registerDoParallel
